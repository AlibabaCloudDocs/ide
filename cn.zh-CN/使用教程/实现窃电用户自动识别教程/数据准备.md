# 数据准备 {#task_1663817 .task}

在数据准备阶段，您需要同步原始数据至MaxCompute。

## 新建数据源 {#section_yea_ozz_xvj .section}

**说明：** 本次实验需要创建MySQL数据源。

1.  单击相应工作空间后的**进入数据集成**。
2.  进入**同步资源管理** \> **数据源**页面，单击**新增数据源**。![新增数据源](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419455074_zh-CN.png)


3.  在新增数据源弹出框中，选择数据源类型为**MySQL**。
4.  填写**MySQL** \> **阿里云数据库（RDS）**对话框中的配置。![填写配置](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419455076_zh-CN.png)

 您可以使用自己的数据源，也可以根据下表中的配置进行填写。

    |配置|说明|
    |:-|:-|
    |**数据源类型**|当前选择的数据源类型为**MySQL** \> **阿里云数据库（RDS）**。|
    |**数据源名称**|数据源名称必须以字母、数字、下划线组合，且不能以数字和下划线开头。此处名称填写为workshop。|
    |**数据源描述**|对数据源进行简单描述，不得超过80个字符。|
    |**适用环境**|可以选择**开发**或**生产**环境。 **说明：** 仅标准模式工作空间会显示此配置。

 |
    |**地区**|选择**华东1-杭州**。|
    |**RDS实例ID**|填写rm-bp1z74n31h36kqv7x。|
    |**RDS实例主账号ID**|填写1486821399873474。|
    |**数据库名**|填写shanyun。|
    |**用户名**|填写xc\_super1。|
    |**用户名/密码**|填写xc\_super1。|

5.  单击**测试连通性**。
6.  测试连通性通过后，单击**完成**。

## 新建业务流程 {#section_ot4_7n4_310 .section}

1.  单击左上角的图标，选择**全部产品** \> **DataStudio（数据开发）**。
2.  右键单击**业务流程**，选择**新建业务流程**。![新建业务流程](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419455124_zh-CN.png)


3.  在新建业务流程对话框中，填写**业务流程名称**和**描述**。
4.  单击**新建**，即可完成业务流程的创建。
5.  进入业务流程开发面板，并向面板中拖入一个虚拟节点（start）和3个数据同步节点（电量下降趋势数据同步、窃电标志数据同步和指标数据同步）分别填写相应的配置后，单击**提交**。![虚拟节点](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419555127_zh-CN.png)

![趋势数据同步](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419555128_zh-CN.png)

![标志数据同步](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419555129_zh-CN.png)


6.  拖拽连线将start节点设置为3个数据同步节点的上游节点。![拖拽](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419555131_zh-CN.png)



## 配置start节点 {#section_240_awd_xxd .section}

1.  双击虚拟节点，单击右侧的**调度配置**。
2.  设置start节点的上游节点为工作空间根节点。 

    由于新版本给每个节点都设置了输入输出节点，所以需要给start节点设置一个输入。此处设置其上游节点为工作空间根节点，通常命名为工作空间名\_root。

    ![根节点](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419555133_zh-CN.png)

3.  配置完成后，单击左上角的![保存](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419555134_zh-CN.png)进行保存。

## 新建表 {#section_zbl_02k_kvv .section}

1.  右键单击业务流程下的**表**，选择**新建表**。![新建表](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419655137_zh-CN.png)


2.  在新建表对话框中填写表名，单击**提交**。 

    此处需要创建3张表，分别存储同步过来的电量下降趋势数据、指标数据和窃电标志数据（trend\_data、indicators\_data和steal\_flag\_data）。

3.  打开创建的表，单击**DDL模式**，分别填写以下相应的建表语句。 

    ``` {#codeblock_cvj_gvy_jm1}
    --电量下降趋势表
    CREATE TABLE `trend_data` (
        `uid` bigint,
        `trend` bigint
    )
    PARTITIONED BY (dt string);
    ```

    ``` {#codeblock_ttu_vsk_our}
    --指标数据
    CREATE TABLE `indicators_data` (
        `uid` bigint,
        `xiansun` bigint,
        `warnindicator` bigint
    )
    COMMENT '*'
    PARTITIONED BY (ds string)
    LIFECYCLE 36000;
    ```

    ``` {#codeblock_cqn_ppn_wuk}
    --窃电标志数据
    CREATE TABLE `steal_flag_data` (
        `uid` bigint,
        `flag` bigint
    )
    COMMENT '*'
    PARTITIONED BY (ds string)
    LIFECYCLE 36000;
    ```

4.  建表语句输入完成后，单击**生成表结构**并**确认**覆盖当前操作。
5.  返回建表页面后，在**基本属性**中输入表的中文名。
6.  完成设置后，分别单击**提交到开发环境**和**提交到生产环境**。![提交环境](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419655141_zh-CN.png)



## 配置数据同步节点 {#section_629_a4d_1my .section}

1.  配置电量下降趋势数据同步节点。 
    1.  双击电量下降趋势数据同步节点，进入节点配置页面。
    2.  选择数据来源。 

        ![数据来源](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419655158_zh-CN.png)

        |配置|说明|
        |--|--|
        |**数据源**|选择**MySQL** \> **workshop**。|
        |**表**|选择MySQL数据源中的表trending。|
        |**数据过滤**|您将要同步数据的筛选条件，暂时不支持limit关键字过滤。SQL语法与选择的数据源一致，此处可以不填。|
        |**切分键**|读取数据时，根据配置的字段进行数据分片，实现并发读取，可以提升数据同步效率。此处可以不填。|

    3.  选择数据去向。 

        ![数据去向](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419655163_zh-CN.png)

        |配置|说明|
        |--|--|
        |**数据源**|选择**ODPS** \> **odps\_first**。|
        |**表**|选择ODPS数据源中的表trend\_data。|
        |**分区信息**|输入要同步的分区列，此处默认为`dt=${bdp.system.bizdate}`。|
        |**清理规则**|选择**写入前清理已有数据**。|
        |**空字符串是否作null**|选择**null**。|

    4.  配置字段映射。![字段映射](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419655186_zh-CN.png)


    5.  配置**通道控制**。 

        ![通道控制](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419655187_zh-CN.png)

        |配置|说明|
        |:-|:-|
        |**任务期望最大并发数**|数据同步任务内，可以从源并行读取或并行写入数据存储端的最大线程数。向导模式通过界面化配置并发数，指定任务所使用的并行度。|
        |**同步速率**|设置同步速率可以保护读取端数据库，以避免抽取速度过大，给源库造成太大的压力。同步速率建议限流，结合源库的配置，请合理配置抽取速率。|
        |**错误记录数**|错误记录数，表示脏数据的最大容忍条数。|
        |**任务资源组**|任务运行的机器，如果任务数比较多，使用默认资源组出现等待资源的情况，建议购买独享数据集成资源或添加自定义资源组，详情请参见[DataWorks独享资源](../../../../cn.zh-CN/产品定价/预付费（包年包月）/DataWorks独享资源.md#)和[新增任务资源](../../../../cn.zh-CN/使用指南/数据集成/常见配置/新增任务资源.md#)。|

    6.  确认当前节点的配置情况，可以进行修改。确认无误后，单击左上角的**保存**。

## 提交业务流程 {#section_a59_gyr_2hj .section}

1.  打开业务流程配置面板，单击左上角的**提交**。![提交业务流程](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419655192_zh-CN.png)


2.  选择提交对话框中需要提交的节点，填写**备注**，勾选**忽略输入输出不一致的告警**。![提交](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419755195_zh-CN.png)


3.  单击**提交**，待显示**提交成功**即可。

## 确认数据是否成功导入MaxCompute {#section_apq_o2j_kj2 .section}

1.  单击左侧导航栏中的**临时查询**，进入临时查询面板。
2.  右键单击**临时查询**，选择**新建节点** \> **ODPS SQL**。![临时查询](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419755200_zh-CN.png)


3.  编写并执行SQL语句，查看导入表trend\_data、indicators\_data和steal\_flag\_data的记录数。 

    ![查询](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/1318796/156576419755202_zh-CN.png)

    **说明：** SQL语句如下所示，其中分区列需要更新为业务日期。例如，任务运行的日期为20190809，则业务日期为201900808。

    ``` {#codeblock_9az_e2j_sd9}
    --查看是否成功写入MaxCompute
    SELECT count(*) from trend_data where dt=业务日期;
    SELECT count(*) from indicators_data where ds=业务日期;
    SELECT count(*) from steal_flag_data where ds=业务日期;
    ```


现在，您已经学习了如何进行数据同步，完成数据的采集，您可以继续学习下一个教程。在该教程中您将学习如何对采集的数据进行计算与分析。详情请参见。

