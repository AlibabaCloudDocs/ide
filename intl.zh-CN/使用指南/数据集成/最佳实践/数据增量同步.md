# 数据增量同步 {#concept_m1y_2y3_r2b .concept}

## 需要同步的两种数据 {#section_ofy_zz3_r2b .section}

需要同步的数据根据数据写入后是否会发生变化，分为不会发生变化的数据（一般是日志数据）和会变化的数据（人员表，例如人员的状态会发生变化）。

## 示例说明 {#section_pfy_zz3_r2b .section}

针对以上两种数据场景，需要设计不同的同步策略，本文以把业务RDS数据库的数据同步到MaxCompute为例进行说明，其他数据源的原理一样。

根据等幂性原则（一个任务多次运行的结果一样，则该任务支持重跑调度，因此该任务若出现错误，清理脏数据会比较容易），每次导入数据都是导入到一张单独的表/分区里，或者覆盖里面的历史记录。

本文定义任务测试时间是2016-11-14，全量同步是在14号进行的，同步历史数据到ds=20161113这个分区中。增量同步的场景配置了自动调度，把增量数据在15号凌晨同步到ds=20161114的分区中。数据里有一个时间字段optime，用来表示这条数据的修改时间，从而判断这条数据是否是增量数据。

## 不变的数据进行增量同步 {#section_b2h_l1j_r2b .section}

由于数据生成后不会发生变化，因此可以很方便地根据数据的生成规律进行分区，较常见的是根据日期进行分区，例如每天一个分区。

**数据准备**

```
drop table if exists oplog;
create table if not exists oplog(
optime DATETIME,
uname varchar(50),
action varchar(50),
status varchar(10)
 );
Insert into oplog values(str_to_date('2016-11-11','%Y-%m-%d'),'LiLei','SELECT','SUCCESS');
Insert into oplog values(str_to_date('2016-11-12','%Y-%m-%d'),'HanMM','DESC','SUCCESS');
```

这里有两条数据作为历史数据，需先做一次全量数据同步，将历史数据同步到昨天的分区。

**操作步骤**

1.  创建MaxCompute表。

    ```
    --创建好MaxCompute表，按天进行分区
    create table if not exists ods_oplog(
     optime datetime,
     uname string,
     action string,
     status string
    ) partitioned by (ds string);
    ```

2.  配置同步历史数据的任务。

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17278/15367271008877_zh-CN.png)

    因为只需执行一次，所以只需操作一次测试即可。测试成功后，进入**数据开发**模块把任务的状态改成暂停（最右边的调度配置）并重新提交/发布，避免任务自动调度执行。

    查看MaxCompute表的结果

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17278/15367271008878_zh-CN.png)

3.  往RDS源头表中多写一些数据作为增量数据。

    ```
    insert into oplog values(CURRENT_DATE,'Jim','Update','SUCCESS');
    insert into oplog values(CURRENT_DATE,'Kate','Delete','Failed'); 
    insert into oplog values(CURRENT_DATE,'Lily','Drop','Failed');
    ```

4.  配置同步增量数据的任务。

    **说明：** 通过配置数据过滤，在15号凌晨进行同步时，可以把14号源头表全天新增的数据查询出来，并同步到目标表增量分区里。

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17278/15367271008879_zh-CN.png)

5.  查看同步结果。

    任务设置调度周期为每天调度，提交/发布后，第二天任务将自动调度执行，执行成功后，可以查看到MaxCompute目标表的数据。

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17278/15367271008880_zh-CN.png)


## 会变的数据进行增量同步 {#section_p3y_32j_r2b .section}

根据数据仓库反映历史变化的特点，建议每天对人员表、订单表等会发生变化的数据进行全量同步，也就是说每天保存的都是全量数据，方便您获取历史数据和当前数据。

真实场景中因为某些特殊情况，需要每天只做增量同步，又因为MaxCompute不支持Update语句进行修改数据，只能用其他方法来实现。下文将为您介绍两种同步策略（全量同步、增量同步）的具体操作。

**数据准备**

```
drop table if exists user ;
create table if not exists user(
    uid int,
    uname varchar(50),
    deptno int,
    gender VARCHAR(1),
    optime DATETIME
    );
--历史数据
insert into user values (1,'LiLei',100,'M',str_to_date('2016-11-13','%Y-%m-%d'));
insert into user values (2,'HanMM',null,'F',str_to_date('2016-11-13','%Y-%m-%d'));
insert into user values (3,'Jim',102,'M',str_to_date('2016-11-12','%Y-%m-%d'));
insert into user values (4,'Kate',103,'F',str_to_date('2016-11-12','%Y-%m-%d'));
insert into user values (5,'Lily',104,'F',str_to_date('2016-11-11','%Y-%m-%d'));
--增量数据
update user set deptno=101,optime=CURRENT_TIME  where uid = 2; --null改成非null
update user set deptno=104,optime=CURRENT_TIME  where uid = 3; --非null改成非null
update user set deptno=null,optime=CURRENT_TIME  where uid = 4; --非null改成null
delete from user where uid = 5;
insert into user(uid,uname,deptno,gender,optime) values (6,'Lucy',105,'F',CURRENT_TIME);
```

**每天全量同步**

1.  创建MaxCompute表。

    ```
    --全量同步
    create table ods_user_full(
        uid bigint,
        uname string,
        deptno bigint,
        gender string,
        optime DATETIME 
    ) partitioned by (ds string);ring);
    ```

2.  配置全量同步任务。

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17278/15367271008887_zh-CN.png)

    **说明：** 需要每天都全量同步，因此任务的调度周期需要配置为天调度。

3.  测试任务，并查看同步后MaxCompute目标表的结果。

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17278/15367271008888_zh-CN.png)

    因为每天都是全量同步，没有全量和增量的区别，所以第二天任务自动调度执行成功后，即可看到数据结果。

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17278/15367271018889_zh-CN.png)

    您可执行`where ds =‘20161114’`获取全量数据。


**每天增量同步**

不推荐使用此方式，只有在极特殊的场景下才考虑。首先这种场景不支持Delete语句，因为被删除的数据无法通过SQL语句的过滤条件查到。当然实际上公司的代码很少直接删除数据，都是使用逻辑删除，将Delete转化为Update进行处理。但是这里毕竟限制了一些特殊的业务场景不能做了，当出现特殊情况可能导致数据不一致。另外还有一个缺点就是同步后要对新增的数据和历史数据做合并。

**数据准备**

需要创建两张表，一张写当前的最新数据，一张写增量数据。

```
--结果表
create table dw_user_inc(
    uid bigint,
    uname string,
    deptno bigint,
    gender string,
    optime DATETIME 
);
--增量记录表
create table ods_user_inc(
    uid bigint,
    uname string,
    deptno bigint,
    gender string,
    optime DATETIME 
)
```

1.  配置任务将全量数据直接写入结果表。

    **说明：** 只需执行一次，执行成功后需进入**数据开发**页面将任务设置暂停。

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17278/15367271018890_zh-CN.png)

    结果如下：

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17278/15367271018891_zh-CN.png)

2.  配置任务将增量数据写入到增量表。

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17278/15367271018892_zh-CN.png)

    结果如下：

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17278/15367271018893_zh-CN.png)

3.  合并数据。

    ```
    insert overwrite table dw_user_inc 
    select 
    --所有select操作，如果ODS表有数据，说明发生了变动，以ODS表为准
    case when b.uid is not null then b.uid else a.uid end as uid,
    case when b.uid is not null then b.uname else a.uname end as uname,
    case when b.uid is not null then b.deptno else a.deptno end as deptno,
    case when b.uid is not null then b.gender else a.gender end as gender,
    case when b.uid is not null then b.optime else a.optime end as optime
    from 
    dw_user_inc a 
    full outer join ods_user_inc b
    on a.uid  = b.uid ;
    ```

    结果如下：

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/17278/15367271018894_zh-CN.png)


由结果可见，Delete的那条记录没有同步成功。

对比上述两种同步方式，可以很清楚看到两种同步方法的区别和优劣。每天增量同步的优点是同步的增量数据量比较小，但是带来的缺点有可能有数据不一致的风险，而且还需要用额外的计算进行数据合并。

如果不是必要情况，会变化的数据进行每天全量同步即可。如果对历史数据希望只保留一定的时间，超出时间的做自动删除，可以设置Lifecycle。

