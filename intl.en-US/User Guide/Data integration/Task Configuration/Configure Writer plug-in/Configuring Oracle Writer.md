# Configuring Oracle Writer {#concept_dzy_j2n_q2b .concept}

In this article we will show you the data types and parameters supported by Oracle Writer and how to configure Writer in both wizard mode and script mode.

The Oracle Writer plug-in provides the ability to write data into the target tables of the primary Oracle database.  At the underlying implementation level, Oracle Writer connects to a remote Oracle database through JDBC, and runs the `insert into...` SQL statement to write data into Oracle. 

**Note:** You must configure the data source before configuring the Oracle Writer plug-in. For more information, see[Configure Oracle data source](reseller.en-US/User Guide/Data integration/Data source configuration/Configure Oracle data source.md#)Configure the Oracle Data Source.

Oracle Writer is designed for ETL developers to import data from data warehouses to Oracle. Oracle Writer can also be used as a data migration tool by DBA and other users.

Oracle Writer uses the data synchronization framework to get the protocol data generated by Oracle Reader. Then it connects to a remote Oracle database through JDBC, and runs the insert into ...  SQL statement to write data into Oracle.

## Type conversion list {#section_h4p_w2n_q2b .section}

Similar to Oracle Reader, Oracle Writer currently supports most data types in Oracle. Check whether your data type is supported.

Oracle Writer converts the data types in Oracle as follows:

|Type Classification|Oracle data type|
|:------------------|:---------------|
|Integer|NUMBER, RAWID, INTEGER, INT, and SMALLINT|
|Floating point|NUMERIC, DECIMAL, FLOAT, DOUBLE PRECISION, and REAL|
|String|LONG, CHAR, NCHAR, VARCHAR, VARCHAR2, NVARCHAR2, CLOB, NCLOB, CHARACTER, CHARACTER VARYING, CHAR VARYING, NATIONAL CHARACTER, NATIONAL CHAR, NATIONAL CHARACTER VARYING, NATIONAL CHAR VARYING, and NCHAR VARYING|
|TIMESTAMP and DATE|Timestamp and date|
|Boolean|BIT and BOOL|
|Binary|BLOB, BFILE, RAW, and LONG RAW|

## Parameter description​ {#section_jn2_gqh_p2b .section}

|Attribute|Description|Required|Default Value|
|:--------|:----------|:-------|:------------|
|datasource|Data source name. It must be identical to the data source name added. Adding data source is supported in script mode.|Yes|None|
|table|Description: Target table name. If the schema information of table is not consistent with the username in the preceding configuration, enter the table information in the schema.table format.|Yes|N/A|
|column|Description: The fields of the target table into which data is required to be written. These fields are separated by commas. For example:`"column": ["id”,”name”,”age”]`.  Use \* if it is required to write data into all columns in sequence.  For example: `"column":["*"]`.|Yes|None|
|preSql|Description: The SQL statement that is run before the data synchronization task is run.  Currently, you can run only one SQL statement in wizard mode, and more than one SQL statement in script mode. For example, clear old data.|No|None|
|postSql|Description: The SQL statement that is run after the data synchronization task is run. Currently, you can run only one SQL statement in wizard mode, and more than one SQL statement in script mode. For example, add a timestamp.|No|None|
|batchSize|Description: The quantity of records submitted in one operation. Setting this parameter can greatly reduce the interactions between CDP and Oracle over the network, and increase the overall throughput.  However, an excessively large value may cause the running process of CDP to become out of memory \(OOM\).|No|1,024|

## Development in wizard mode {#section_bp2_wsh_p2b .section}

1.  Choose source

    Configuration item descriptions:

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/16251/15413889558194_en-US.png)

    Parameters:

    -   Data source: The datasource in the preceding parameter description. Enter the data source name you configured.
    -   Table: The table in the preceding parameter description. Select the table to be synchronized.
    -   Prepared statement before import: preSql in the preceding parameter description, namely, the SQL statement that is run before the data synchronization task is run.
    -   Post-import completion statement: postSql in the preceding parameter description, which is the SQL statement that is run after the data synchronization task is run.
    -   Primary key conflict: writeMode in the preceding parameter description. You can select the expected import mode.
2.  Field mapping: The column in the preceding parameter description.

    The Source Table Field on the left maps with the Target Table Field on the right. Click **Add Line**, and then a field is added. Hover the cursor over a line, click **Delete**, and then the line is deleted.

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/16251/15413889558195_en-US.png)

    -   In-row mapping: You can click **Enable Same-Line Mapping** to create a mapping for the same row. Note that the data type must be consistent.
    -   Automatic formatting: The fields are automatically sorted based on corresponding rules.
3.  Channel control

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/16221/15413889557675_en-US.png)

    Parameters:

    -   DMU: A unit which measures the resources \(including CPU, memory, and network bandwidth\) consumed during data integration. One DMU represents the minimum amount of resources used for a data synchronization task.
    -   Concurrent job count: Maximum number of threads used to concurrently read data from or write data into the data storage media in a data synchronization task. In wizard mode, configure a concurrency for the specified task on the wizard page.
    -   The maximum number of errors indicates the maximum number of dirty data records.
    -   Task Resource Group: the machine on which the task runs, if the number of tasks is large, the default Resource Group is used to wait for a resource, it is recommended that you add a Custom Resource Group \(currently only 1 East China, east China 2 supports adding custom resource groups\). For more information, see[Add scheduling resources](reseller.en-US/User Guide/Data integration/Common configuration/Add scheduling resources.md#).

## Development in script mode {#section_cp2_wsh_p2b .section}

Configure a job to write data into Oracle:

```
{
    "type":"job",
    "version": 2.0", // version number
    "steps":[
        {//The following is a reader template. You can find the corresponding reader plug-in documentations.
            "stepType":"stream",
            "parameter":{},
            "name":"Reader",
            "category":"reader"
        },
        {
            "stepType": "oracle", // plug-in name
            "parameter": {
                "postSql": [], // SQL statement executed after the data synchronization task is executed
                "datasource":"",
                "session": [], // database connection session parameters
                "column": [// Field
                    "id",
                    "name"
                ],
                "encoding": "UTF-8", // encoding format
                "batchSize": "1024", // number of records submitted in one batch size
                "table":"", // table name
                "postSql": []// SQL statement executed after the data synchronization task is executed
            },
            "name":"Writer",
            "category":"writer"
        }
    ],
    "setting":{
        "errorLimit":{
            "record": "0"//Number of error records
        },
        "speed":{
            "throttle":false,//False indicates that the traffic is not throttled and the following throttling speed is invalid. True indicates that the traffic is throttled.
            "concurrent": "1", //Number of concurrency
            "dmu": 1 //DMU Value
        }
    },
    "order":{
        "hops":[
            {
                "from":"Reader",
                "to":"Writer"
            }
        ]
    }
}
```

