# Configure HybridDB for MySQL Writer {#concept_rjl_j1c_5fb .concept}

This topic describes the data types and parameters supported by HybridDB for MySQL Writer and how to configure it in both Wizard and Script modes.

HybridDB for MySQL Writer writes data into a HybridDB for MySQL database. At the underlying implementation level, HybridDB for MySQL Writer connects to a remote HybridDB for MySQL database through JDBC, and runs the `INSERT INTO…` or `REPLACE INTO…` SQL statement to write data into the database. Internally, data is submitted to the database in batches, and therefore the database must use the InnoDB engine.

**Note:** You must configure a data source before configuring HybridDB for MySQL Writer. For more information, see [Configure a HybridDB for MySQL data source](intl.en-US/User Guide/Data integration/Data source configuration/Configure HybridDB for MySQL data source.md#).

HybridDB for MySQL Writer is designed for ETL developers to import data from data warehouses to HybridDB for MySQL. HybridDB for MySQL Writer can also be used as a data migration tool by DBA and other users. HybridDB for MySQL Writer obtains protocol data generated by a reader through the Data Integration framework. The generated protocol data varies with the writeMode attribute that you have configured.

**Note:** The task must have the `INSERT INTO... or REPLACE INTO…` permission. Whether other permissions are required depends on the SQL statements specified in the preSql and postSql attributes in the configured task.

## Type conversion list {#section_qqr_b4r_5fb .section}

Similar to HybridDB for MySQL Reader, HybridDB for MySQL Writer supports most data types in HybridDB for MySQL. Before configuring HybridDB for MySQL Writer, check whether the data type is supported .

HybridDB for MySQL Writer converts the data types in HybridDB for MySQL as follows:

|Type classification|HybridDB for MySQL data type|
|:------------------|:---------------------------|
|Integer|Int, Tinyint, Smallint, Mediumint, Bigint, and Year|
|Float|Float, Double, and Decimal|
|String|Varchar, Char, Tinytext, Text, Mediumtext, and Longtext|
|Date and time|Date, Datetime, Timestamp, and Time|
|Boolean|Boolean|
|Binary|Tinyblob, Mediumblob, Blob, Longblob, and Varbinary|

## Parameter description {#section_vpb_wfr_5fb .section}

|Parameter|Description|Required|Default value|
|:--------|:----------|:-------|:------------|
|datasource|The data source name. The name must be identical to the added data source name. Script Mode supports adding data sources.|Yes|None|
|table|The destination table name.|Yes|None|
|writeMode|The Write Mode, which can be set to insert or replace.-   REPLACE INTO…: When there are no primary key or unique index conflicts, the action is the same as that of INSERT INTO. If a conflict occurs, the fields in new rows replace all fields in original rows.
-   INSERT INTO...: If a primary key or unique index conflict occurs, data cannot be written into the conflicting rows, and is classified as dirty data.
-   INSERT INTO table \(a,b,c\) VALUES \(1,2,3\) ON DUPLICATE KEY UPDATE…: If no primary key conflict or unique index conflict occurs, the action is the same as that of INSERT INTO. If a conflict occurs, the fields in new rows replace the specified fields in original rows.

|No|Insert|
|column|The required destination table fields into which data is written. These fields are separated with commas \(,\). For example, `"column": ["id","name","age"]`. If you want to write all columns in turn, use the asterisk \(\*\). For example: `"column": ["*"]`.|Yes|None|
|preSql|The SQL statement that runs before running the data synchronization task. For example, you can clear old data before data synchronization. Currently, you can run only one SQL statement in Wizard Mode, and multiple SQL statements in Script Mode.|No|None|
|postSql|The SQL statement that runs after running the data synchronization task. For example, you can add a timestamp after data synchronization. Currently, you can run only one SQL statement in Wizard Mode, and multiple SQL statements in Script Mode.|No|None|
|batchSize|The number of records submitted at a time. This parameter can greatly reduce the interaction frequency between Data Integration and HybridDB for MySQL on the network, and increase the overall throughput. However, an excessively large value may lead to OOM during the data synchronization process.|No|1024|

## Development in Wizard Mode {#section_jvk_sgr_5fb .section}

1.  **Specify data sources**

    Configure the source and destination of data for a synchronization task as follows.

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/62205/155176504439919_en-US.png)

    |Parameter|Description|
    |:--------|:----------|
    |**Data Source**|The datasource parameter in the preceding parameter description. Select the configured data source.|
    |**Table**|The table parameter in the preceding parameter description. Select the destination table.|
    |**Statements Run Before Import**|The preSQL parameter in the preceding parameter description. Enter the SQL statement that runs before running the data synchronization task.|
    |**Statements Run After Import**|The postSql parameter in the preceding parameter description. Enter the SQL statement that runs after running the data synchronization task.|
    |**Primary Key Violation**|The writeMode parameter in the preceding parameter description. Select the expected write mode.|

2.  Configure mappings of fields \(the column parameter in the preceding parameter description\).

    Each source table field on the left maps a destination table field on the right. To add a mapping, and click **Add**. To delete the current mapping, move the cursor over a line and click **Delete**.

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/62195/155176504432070_en-US.png)

    |Configuration|Description|
    |:------------|:----------|
    |**Map Fields with the Same Name**|Click **Map Fields with the Same Name** to establish a mapping between fields with the same name. Note that the data type must be consistent.|
    |**Map Fields in the Same Line**|Click **Map Fields in the Same Line** to establish a mapping for the same row. Note that the data type must be consistent.|
    |**Remove Mappings**|Click **Remove Mappings** to remove established mappings.|
    |**Auto Layout**|The fields are automatically sorted based on specified rules.|

3.  **Configure channel control**

    ![](http://static-aliyun-doc.oss-cn-hangzhou.aliyuncs.com/assets/img/62209/155176504432018_en-US.png)

    |Parameter|Description|
    |:--------|:----------|
    |**DMU**|The unit that measures the resources, including CPU, memory, and network resources consumed by Data Integration. A DMU represents the minimum operating capability of a Data Integration task, that is, the data synchronization processing capability given to the limited CPU, memory, and network resources.|
    |**Concurrent Jobs**|The maximum number of threads used to concurrently read data from the source or write data into the data storage media in a data synchronization task. In Wizard Mode, you can configure the concurrency for a task on the wizard page.|
    |**Dirty Data Records Allowed**|The maximum number of errors or dirty data records allowed.|
    |**Task Resource Group**|The machines on which tasks are run. If a large number of tasks run on the default resource group, some tasks may be delayed due to insufficient resources. In this case, we recommend that you add a custom resource group. Currently, a custom resource group can be added only in China \(Hangzhou\) and China \(Shanghai\). For more information, see [Add task resources](intl.en-US/User Guide/Data integration/Common configuration/Add task resources.md#).|


## Development in Script Mode {#section_vw5_p3r_5fb .section}

The following code is an example of configuration in Script Mode. For more information about parameters, see the preceding parameter description.

```
{
    "type": "job",
    "steps": [
        {
            "parameter": {},
        {
            "parameter": {
                "postSql": [],// The SQL statement to be run after the data synchronization task is run.
                "datasource": "px_aliyun_hymysql",// The data source name.
                "column": [// The destination table columns.
                    "id",
                    "name",
                    "sex",
                    "salary",
                    "age",
                    "pt"
                ],
                "writeMode": "insert",// The write mode.
                "batchSize": 256,// The number of records submitted at a time.
                "encoding": "UTF-8",// The encoding format.
                "table": "person_copy",// The destination table name.
                "preSql": [],// The SQL statement to be run before the data synchronization task is run.
            },
            "name": "Writer",
            "category": "writer"
        }
    ],
    "version": "2.0",// The version number.
    "order": {
        "hops": [
            {
                "from": "Reader",
                "to": "Writer"
            }
        ]
    },
    "setting": {
        "errorLimit": {// The maximum number of errors allowed.
            "record": ""
        },
        "speed": {
            "concurrent": 7,// The number of concurrent threads.
            "throttle": true,// Indicates whether to throttle the transmission rate.
            "mbps": 1,// The maximum transmission rate.
            "dmu": 5// The DMU value.
        }
    }
}
```

